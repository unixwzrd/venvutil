#!/bin/bash
#
# BUILD REFERENCE
#
# BUILD:    macOS-webui COnfiguration File
# CONFIG:   A
# DESC:     This is part of a group of builds to test stability and cmopatability of libraries. 
#
#               pytorch          - Condda Edition (R)
#               webui-macOS      - Package requitements for webui
#               llama-cpp-python - llama.cpp GGUF bindings for Python
#               llama-cpp        - llama.cpp for support scripts and more
#               oobapkgs         - Packages
#
# OPTIONS:  --no-deps
#
#
#
#
# The VENV for Python set up using Conda takes teh form of:
#
#       BUILDID         - This is the APP_CODE below and all VENV's for this build
#                         stack will be prefixed with this BUILDID.
#       SEQUENCE        - The sequence or stge in the build process.  Starting with 00
#                         it is incremented as packages are layered on top.  Generally
#                         a new sequence is generated for each step/package installed
#                         To allow for rollback of branching from that point in case you
#                         wish to install different versions of a package on top of another
#                         or roll-back to a package and install a different version of
#                         the packabe layered on top of it.
#       DESCRIPTION     - A brief description for personal or project reference as to the
#                         build type of other attributes to be tracked fo that stage of the
#                         build. Descriptions will be generated based oon the package installed
#                         during a particular step in th ebuild, specified by PACKAGE_INSTALL
#                         order.
#
# The description will be APP_CODE.00.PACKAGE-CONFIG
#
# Application code prefix for the VENV builds. Two or three letters to allow
# grouping of the VENV's when getting an environment listing.
APP_CODE="blda"

# BUILD_BASE is the base directory all packages will be installed in.
# BUILD_DIR id the directory all packages for a build configuration will be downloaded and built in
# other code wil be staged, configured, built and installed from.
# The default location is the current directory.
BUILD_BASE=${PWD}
BUILD_DIR=${PWD}/${APP_CODE}


# N_CPU is the number of CPU's in the mnachine available for doing make operations
# This si so we can maxumize parallelism during make operations.
# DEFAULT:  - ( cpu count - 1 ) * 2
#
#               Set to different number to throttle make operations or set to ""
#               which will maximize paralleism, but may have unintended side-effects.
#               Such as filling up th eterminal buffer, causing it to initiate printing
#               the terminal output, could also inadvertently halt make operations.
# 
# VALUES        ""  - Will maximize parallelism on make operations.
#               int - Number of CPU or CPU coires you wiush to do on any builds which use
#                     "make" or "cmake"
# N_CPU=12
 N_CPU=$(( ( $(sysctl -n hw.ncpu) - 1 ) * 2 ))

# PACKAGE_INSTALL branch and layer ordering for each package install/re-install/recompile
#
# Package swquence by package name. There are two columns in this.
#
# PACKAGE     PAckage name to be installed.
#
# *INSTYP*    Install type, what sort of installation this is going to be, Once, New, Re-build/install
# UNUSED        O   - Install once for whole system, like a library or binary executable to install
#                     in /usr/local
#               N   - New install which has not been installed in any or th eprior VENVs.
#               R   - Re-install/compile/build for each VENV it's already been installed in.
#               I   - Install in all VENVs (Same as R type)
#             
# PAACKAGE  - The package in sequence corresponding to the PACKAGE in PACKAGE_CONFIG.
#
PACKAGE_INSTALL=(
#    PACKAGE              | INSTYPE
#   "numpy                | I "
    "numpy                | I "
    "pytorch              | I "
    "webui-macOS          | O "
    "oobapkgs             | O "
    "llama-cpp-python     | I "
    "llama-cpp            | I "
#   "oobaxtns             | O "
)
#PI_PACKAGE=0
#PI_INSTYPE=1

# Internal steps done to set up th einitial Conda VENV for an application.
__INTERNAL_STEPS=(
    "__CONDA"
    "__PYTHON_BASE"
    "__CREATE_APP_BASE"
#   "__CMAKE"
#   "__BLIS"
#   "__OPENBLAS"
)


# PACKAGE_CONFIG specifications for each Python or Conda package installation.
# TODO - The layering/Branching is not implemented yet, right now things are layered
#        from a starting base with the required version of Python.
# TODO - Add function calling ability and adding functions to this config.sh file.
# TODO - "Sandboxing" of libraries in their own "PREFIX" location like /usr/local
#        but rather a unique location so runtime and static linkers will use that
#        location for lobraries instead of th edefault.
#
# CONFIG      - unique build identifier
# DESCRIPRION - Long Description of the configuration
# PACKAGE     - The PyPi or Conda package identifier for the modulr or package being installed.
# ALT_NAME    - For packages like PyTorch wihich have a difefrent or alternate name depending
#               on th epackage source. The alternate name will be used if it exists. 
# VERSION     - PAckage version for Python packatesuch as for llama-cpp-python - 0.2.7
# PRE_FLAGS   - Pre Conda/Pip flags passed
# METHOD      - Method of install or package manager to use ( pip | conda | git | func )
# POST_FLAGS  - Installer invication flags
#
PACKAGE_CONFIG=(
#    CONFIG     | DESCRIPTION                                                       | PACKAGE   | ALT_NAME | PRE_FLAGS                                         | METHOD|  POST_FLAGS
#   "base       | Standard Pip install                                              | numpy     | |                                                            | pip   | "
#   "conda      | Standard Conda package install                                    | numpy     | |                                                            | conda | -y"
#   "recomp     | Standard Pip recompile - non-binary install                       | numpy     | |                                                            | pip   | --force-reinstall --no-cache --no-binary :all: --compile"
#   "np-1-26GPU | Pip install using Accelerate Framework NumPy 1.26.0               | numpy     | | CFLAGS="-I/System/Library/Frameworks/vecLib.framework/Headers -Wl,-framework -Wl,Accelerate -framework Accelerate" | pip | --force-reinstall --no-deps --no-cache --no-binary :all: --compile -Csetup-args=-Dblas=accelerate -Csetup-args=-Dlapack=accelerate -Csetup-args=-Duse-ilp64=true
#   "np-1-26GPU | Pip install using Accelerate Framework NumPy 1.26.0               | numpy     | | NPY_BLAS_ORDER='accelerate' NPY_LAPACK_ORDER='accelerate'  | pip   | --force-reinstall --no-cache --no-binary :all: --compile"
#   "accelerate | Pip install using Accelerate Framework where possible             | numpy     | | NPY_BLAS_ORDER='accelerate' NPY_LAPACK_ORDER='accelerate'  | pip   | --force-reinstall --no-cache --no-binary :all: --compile"
#   "oblas      | Pip Install recompile using OpenBLAS                              | numpy     | | NPY_BLAS_ORDER='openblas' NPY_LAPACK_ORDER='openblas'      | pip   | --force-reinstall --no-cache --no-binary :all: --compile"
#   "blis       | Pip Install recompile using BLIS                                  | numpy     | | NPY_BLAS_ORDER='blis'                                      | pip   | --force-reinstall --no-cache --no-binary :all: --compile"
#   "blisblas   | Pip Install recompile using BLIS for OpenBLAS for LAPACK          | numpy     | | NPY_BLAS_ORDER='blis' NPY_LAPACK_ORDER='openblas'          | pip   | --force-reinstall --no-cache --no-binary :all: --compile"
#   "pip        | Stangard pip install for Torch                                    | pytorch   | torch |                                                      | pip   | torchvision torchaudio"
#   "base       | Base Conda install for Torch                                      | pytorch   | |                                                            | conda | torchvision torchaudio -c pytorch --force-reinstall --no-deps -y"
    "nightly    | Nughtly build for PyTorchrch                                      | pytorch   | torch |                                                      | pip   | --upgrade --no-deps --force-reinstall --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu"
#   "llama      | Stangard pip install for lama-cpp-python                          | llama-cpp-python==0.1.78 | | CMAKE_ARGS='-DLLAMA_METAL=on' FORCE_CMAKE=1 | pip   | --force-reinstall --no-deps"
    "llama      | Stangard pip install for lama-cpp-python                          | llama-cpp-python | | NPY_BLAS_ORDER='accelerate' NPY_LAPACK_ORDER='accelerate' CMAKE_ARGS='-DLLAMA_METAL=on' FORCE_CMAKE=1 | pip   | --force-reinstall --no-cache --no-binary :all: --compile --no-deps"
    "webui      | Oobabooga install                                                 | webui-macOS | |                                                          | git   | clone https://github.com/unixwzrd/text-generation-webui-macos webui-macOS"
    "llama-cpp  | llama.cpp installation for GGUF utilities                         | llama-cpp | |                                                            | git   | clone https://github.com/ggerganov/llama.cpp "
    "llama-GGUF | llama.cpp installation for GGUF utilities                         | gguf      | |                                                            | pip   | --install --nocache "
    "oobapkg    | Install oobagooba's packages using a function call                | oobapkgs  | |                                                            | func  | "
#   "oobaxtns   | oobabooga extensions                                              | oobaextn  | |                                                            | func  | "
)
#PC_CONFIG=0
#PC_DESC=1
#PC_PACKAGE=2
#PC_ALT_NAME=3
#PC_PRE_FLAGS=4
#PC_METHOD=5
#PC_POST_FLAGS=6

